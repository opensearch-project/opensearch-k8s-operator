nodeSelector: {}
tolerations: []
manager:
  extraEnv: []
  resources:
    limits:
      cpu: 200m
      memory: 500Mi
    requests:
      cpu: 100m
      memory: 350Mi

  livenessProbe:
    failureThreshold: 3
    httpGet:
      path: /healthz
      port: 8081
    periodSeconds: 15
    successThreshold: 1
    timeoutSeconds: 3
    initialDelaySeconds: 10

  readinessProbe:
    failureThreshold: 3
    httpGet:
      path: /readyz
      port: 8081
    periodSeconds: 15
    successThreshold: 1
    timeoutSeconds: 3
    initialDelaySeconds: 10

# Set securityContext for manager
  securityContext:
    parallelRecoveryEnabled: true
    allowPrivilegeEscalation: false
#    runAsUser: 1000
#    runAsGroup: 3000
#    fsGroup: 2000
  # Set this to false to disable the experimental parallel recovery in case you are experiencing problems



  image:
    repository: public.ecr.aws/opsterio/opensearch-operator
    ## tag default uses appVersion from Chart.yaml, to override specify tag tag: "v1.1"
    tag: ""
    pullPolicy: "Always"

  dnsBase: cluster.local

  # If a watchNamespace is specified, the manager's cache will be restricted to
  # watch objects in the desired namespace. Defaults is to watch all namespaces.
  watchNamespace:

kubeRbacProxy:
  resources:
    limits:
      cpu: 50m
      memory: 50Mi
    requests:
      cpu: 25m
      memory: 25Mi

  livenessProbe:
    failureThreshold: 3
    tcpSocket:
      port: 8443
    periodSeconds: 15
    successThreshold: 1
    timeoutSeconds: 3
    initialDelaySeconds: 10

  readinessProbe:
    failureThreshold: 3
    tcpSocket:
      port: 8443
    periodSeconds: 15
    successThreshold: 1
    timeoutSeconds: 3
    initialDelaySeconds: 10

   securityContext:
#    runAsUser: 1000
#    runAsGroup: 3000
#    fsGroup: 2000
  image: 
    repository: "gcr.io/kubebuilder/kube-rbac-proxy"
    tag: "v0.8.0"